import numpy as np 
import pandas as pd 
import re #Regular expressions 
import nltk 
import matplotlib.pyplot as plt 
from nltk.corpus import stopwords 
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.ensemble import RandomForestClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.model_selection import train_test_split 
from google.colab import files 
uploaded = files.upload() 
dataset = pd.read_csv('/content/Coronavirus Tweets.csv', encoding='ISO-8859-1') 
print(dataset.shape) 
print(dataset.head(5)) 
features = dataset.iloc[:, 4].values 
labels = dataset.iloc[:, 5].values 
print(labels) 
processed_features = [] 
for sentence in range(0, len(features)): 
# Remove all the special characters 
processed_feature = re.sub(r'\W', ' ', str(features[sentence])) 
# remove all single characters 
processed_feature= re.sub(r'\s+[a-zA-Z]\s+', ' ', processed_feature) 
# Remove single characters from the start 
processed_feature = re.sub(r'\^[a-zA-Z]\s+', ' ', processed_feature) 
# Substituting multiple spaces with single space 
processed_feature = re.sub(r'\s+', ' ', processed_feature, flags=re.I) 
    # Removing prefixed 'b' 
    processed_feature = re.sub(r'^b\s+', '', processed_feature) 
 
    # Converting to Lowercase 
    processed_feature = processed_feature.lower() 
 
    processed_features.append(processed_feature) 
 
 
nltk.download('stopwords') 
vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english')) 
processed_features = vectorizer.fit_transform(processed_features).toarray() 
print(processed_features) 
 
X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0) 
 
text_classifier = RandomForestClassifier(n_estimators=200, random_state=0) 
text_classifier.fit(X_train, y_train) 
 
 
predictions = text_classifier.predict(X_test) 
 
print(accuracy_score(y_test, predictions)) 
 
 
from sklearn import metrics 
import itertools 
def plot_confusion_matrix(cm, classes, 
                          normalize=False, 
                          title='Confusion matrix', 
                          cmap=plt.cm.Blues): 
 
    plt.imshow(cm, interpolation='nearest', cmap=cmap) 
    plt.title(title) 
    plt.colorbar() 
    tick_marks = np.arange(len(classes)) 
    plt.xticks(tick_marks, classes) 
    plt.yticks(tick_marks, classes) 
 
    thresh = cm.max() / 2. 
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): 
        plt.text(j, i, cm[i, j], 
                 horizontalalignment="center", 
                 color="white" if cm[i, j] > thresh else "black") 
 
    plt.tight_layout() 
    plt.ylabel('True label') 
    plt.xlabel('Predicted label') 
 
cm = metrics.confusion_matrix(y_test, predictions, labels=['negative', 'neutral', 'positive','Extremely 
Negative','Extremely Positive']) 
plot_confusion_matrix(cm, classes=['negative', 'neutral', 'positive','Extremely Negative','Extremely Positive'])
